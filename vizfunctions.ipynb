{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a  graph\n",
    "\n",
    "# 1048576\n",
    "def create_graph(n):\n",
    "    # Take the first edges -- this is a list\n",
    "    first_edges = list(edge_df.iloc[:n]['source_target_key'])\n",
    "\n",
    "    # Convert each edge into a tuple\n",
    "    edge_tuples = lambda x: tuple(map(int,x.split(';')))\n",
    "\n",
    "    # Put all those tuples in a list\n",
    "    edge_list = list(map(edge_tuples, first_edges))\n",
    "\n",
    "    # Add edges to graph\n",
    "    geneGraph.add_edges_from(edge_list)\n",
    "\n",
    "    # Weighting edges on DIOPT scores\n",
    "    diopt_dict = {}\n",
    "\n",
    "    for index, edge in enumerate(edge_list):\n",
    "        diopt_dict[edge] = edge_df.iloc[index]['interaction_count']\n",
    "\n",
    "    nx.set_edge_attributes(geneGraph, diopt_dict, 'weight')\n",
    "\n",
    "    # Add bidirectional edges based on reciprocal value\n",
    "    bidirectional_edges = []\n",
    "\n",
    "    for index, edge in enumerate(edge_list):\n",
    "        reciprocal = edge_df.iloc[index]['reciprocal']\n",
    "    if reciprocal:\n",
    "        reversed_edge = (edge[1], edge[0])\n",
    "        bidirectional_edges.append(reversed_edge)\n",
    "\n",
    "    # Adding edges to graph\n",
    "    geneGraph.add_edges_from(bidirectional_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes color spectrum based on publication count\n",
    "\n",
    "# Map values to colors based on color map\n",
    "def get_colors(nodes, cmap):\n",
    "    if not nodes:\n",
    "        return {}\n",
    "    values = list(nodes.values())\n",
    "    norm = mcolors.Normalize(vmin=min(numpy.log1p(values)), vmax=max(numpy.log1p(values)))   # normalizing all values on a scale of 0 to 1 for coloring\n",
    "    cmap = cm.get_cmap(cmap)\n",
    "    return {node: cmap(norm(value)) for node, value in nodes.items()}\n",
    "\n",
    "# Apply colormap to each category's nodes and collect colors\n",
    "def nodes_apply_colormap(G):\n",
    "    # Creating a dict and storing all genes\n",
    "    disease_assoc = {}\n",
    "    non_disease_assoc = {}\n",
    "    non_omim = {}\n",
    "    merged = {}\n",
    "    for node in G.nodes:\n",
    "        if node not in node_df.index:\n",
    "            merged[node] = 1\n",
    "            continue\n",
    "        disease_cat = node_df.loc[node]['disease_assoc_cat']\n",
    "        if disease_cat == 'disease_assoc':\n",
    "            disease_assoc[node] = node_df.loc[node]['publication_count']\n",
    "        elif disease_cat == 'non_disease_assoc':\n",
    "            non_disease_assoc[node] = node_df.loc[node]['publication_count']\n",
    "        elif disease_cat == 'non_omim':\n",
    "            non_omim[node] = node_df.loc[node]['publication_count']\n",
    "        else:\n",
    "            merged[node] = 1\n",
    "    # Identifying base colors for each category\n",
    "    base_colors = {'disease_assoc':'Reds', 'non_disease_assoc':'Blues', 'non_omim': 'Grays', 1:'Grays'}\n",
    "\n",
    "    # Mapping the categories to each other to normalize\n",
    "    all_nodes = {'disease_assoc': disease_assoc,'non_disease_assoc': non_disease_assoc, 'non_omim': non_omim, 1:merged}\n",
    "\n",
    "    # Storing node colors in a list\n",
    "    node_colors = []\n",
    "    for category, nodes in all_nodes.items():\n",
    "        if category not in base_colors:\n",
    "            print(f\"Category {category} is not in base colors\")\n",
    "        else:\n",
    "            cmap_name = base_colors[category]\n",
    "            colors = get_colors(nodes, cmap_name)\n",
    "            if category == 'unknown':\n",
    "                colors = {node: (0, 0, 0, 1) for node in nodes} # Making 'unknown' nodes black\n",
    "            node_colors.extend(colors[node] for node in G.nodes if node in colors)\n",
    "    return node_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(list_of_lists):\n",
    "    pairs = []\n",
    "    for sublist in list_of_lists:\n",
    "        for i in range(len(sublist) - 1):\n",
    "            pairs.append((sublist[i], sublist[i + 1]))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coloring edges by 6 sections of interaction_type\n",
    "\n",
    "# GPT's 6 sections of the 84 items\n",
    "\n",
    "def color_edge_section(G):\n",
    "    genetic_interactions = ['cisphenotypic genetic ','mutual genetic over-su','association', 'genetic interaction', 'genetic suppression', 'genetic suppression (p', 'genetic suppression (c', 'genetic enhancement', 'genetic epistasis (sen', 'phenotypic suppression', 'asynthetic genetic int', 'cisphenotypic co-suppr', 'opposing genetic epist', 'minimal genetic epista', 'synthetic growth defec', 'transphenotypic enhanc', 'transphenotypic geneti', 'genetic over-suppressi', 'negative genetic inter', 'positive genetic inter']\n",
    "    physical_interactions = ['self interaction','physical association', 'direct interaction', 'colocalization', 'proximity', 'protein cleavage', 'disulfide bond', 'Co-localization', 'Co-fractionation', 'Co-purification', 'Co-crystal Structure', 'Protein-peptide', 'Protein-RNA']\n",
    "    post_translational_modifications = ['phosphorylation','demethylation reaction', 'phosphorylation reacti', 'acetylation reaction', 'covalent binding', 'cleavage reaction', 'dephosphorylation reac', 'ubiquitination reactio', 'methylation reaction', 'deacetylation', 'cleavage', 'dephosphorylation', 'methylation', 'ubiquitination', 'deformylation reaction']\n",
    "    experimental_methods = ['Affinity Capture-RNA', 'Affinity Capture-Weste', 'Affinity Capture-MS', 'Two-hybrid', 'Biochemical Activity', 'Reconstituted Complex', 'Negative Genetic', 'Positive Genetic', 'PCA', 'FRET', 'Proximity Label-MS', 'Far Western', 'Affinity Capture-Lumin']\n",
    "    synthetic_rescue_and_dosage_interactions = ['dosage lethality (sens','synthetic genetic inte', 'mutual genetic enhance', 'maximal genetic epista', 'synthetic rescue (sens', 'dosage rescue (sensu B', 'synthetic rescue (sens', 'synthetic lethality (s', 'synthetic haploinsuffi', 'dosage rescue (sensu b', 'dosage growth defect (', 'Synthetic Rescue', 'Synthetic Lethality', 'Dosage Lethality', 'Dosage Rescue',  'Dosage Growth Defect', 'Synthetic Growth Defec', 'Synthetic Haploinsuffi']\n",
    "    phenotypic_interactions = ['monophenotypic genetic', 'phenotypic enhancement', 'putative self interact', 'cisphenotypic inter-su', 'cisphenotypic inter-suppr', 'Phenotypic Suppression', 'Phenotypic Enhancement']\n",
    "\n",
    "    # Creating a dict that assigns each interaction_type to its respective section\n",
    "    interaction_section_dict = {}\n",
    "    for index, row in edge_df.iterrows():\n",
    "        edge = (row['source'], row['target'])\n",
    "        interaction_type = row['interaction_type']\n",
    "        if interaction_type in genetic_interactions:\n",
    "            interaction_section_dict[edge] = {'category':'Genetic Interaction'}\n",
    "        elif interaction_type in physical_interactions:\n",
    "            interaction_section_dict[edge] = {'category':'Physical Interaction'}\n",
    "        elif interaction_type in post_translational_modifications:\n",
    "            interaction_section_dict[edge] = {'category':'Post Translational Modification'}\n",
    "        elif interaction_type in experimental_methods:\n",
    "            interaction_section_dict[edge] = {'category':'Experimental Method'}\n",
    "        elif interaction_type in synthetic_rescue_and_dosage_interactions:\n",
    "            interaction_section_dict[edge] = {'category':'Synthetic Rescue and Dosage Interaction'}\n",
    "        elif interaction_type in phenotypic_interactions:\n",
    "            interaction_section_dict[edge] = {'category':'Phenotypic Interaction'}\n",
    "        else:\n",
    "            print(f'edge color failed for {interaction_type}')\n",
    "            interaction_section_dict[edge] = {'category':'Unknown'}\n",
    "\n",
    "\n",
    "    # Assigning attributes to edge\n",
    "    nx.set_edge_attributes(G, interaction_section_dict)\n",
    "\n",
    "    # Creating a color map that maps each section to a color\n",
    "    edge_section_color_map = {'Genetic Interaction':'orange', 'Physical Interaction':'yellow', 'Post Translational Modification':'green','Experimental Method':'purple','Synthetic Rescue and Dosage Interaction':'pink','Phenotypic Interaction':'brown', 'Unknown':'black'}\n",
    "\n",
    "    edge_colors_int_section = [edge_section_color_map.get(G.edges[edge].get('category', 'Unknown'), 'black') for edge in G.edges]    \n",
    "    # edge_colors_int_section = [edge_section_color_map[G.edges[edge]['category']] for edge in G.edges]\n",
    "    return edge_colors_int_section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing style of edges by interaction_cat\n",
    "\n",
    "def edge_style(G):\n",
    "    # Creating a dictionary that assigns edges to their interaction_cat in a dict\n",
    "    int_cat_dict = {}\n",
    "    for index,edge in enumerate(G.edges):\n",
    "        interaction_cat = edge_df.loc[index]['interaction_cat']\n",
    "        if interaction_cat == 'physical':\n",
    "            int_cat_dict[edge] = {'category':'physical'}\n",
    "        elif interaction_cat == 'genetic':\n",
    "            int_cat_dict[edge] = {'category':'genetic'}\n",
    "        else:\n",
    "            print('category not found')\n",
    "            int_cat_dict[edge] = {'category':'unknown'}\n",
    "\n",
    "    # Assigning attributes to edge\n",
    "    nx.set_edge_attributes(G, int_cat_dict)\n",
    "\n",
    "    # Creating a style map for the categories to colors\n",
    "    edge_cat_style_map = {'physical':'dotted', 'genetic':'solid', 'unknown':'dashed'}\n",
    "    edge_styles_int_cat = [edge_cat_style_map[G.edges[edge]['category']] for edge in G.edges]\n",
    "    return edge_styles_int_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random walk (second order)\n",
    "\n",
    "def second_order_random_walk(graph, steps, n, p, q): #graph, length of walk, number of walks per node, return probability, in-out probability\n",
    "    for start_node in graph.nodes():\n",
    "        for _ in range(n):  # walk iterations per node\n",
    "            walk = [start_node]\n",
    "            current_node = start_node\n",
    "            previous_node = None\n",
    "            \n",
    "            while len(walk)<=steps:\n",
    "            #for _ in range(steps): # length of walk\n",
    "                neighbors = list(graph.neighbors(current_node))\n",
    "                if not neighbors:\n",
    "                    break\n",
    "\n",
    "                if previous_node is None:\n",
    "                    # First step, no previous node\n",
    "                    next_node = random.choice(neighbors)\n",
    "                else:\n",
    "                    # Adjusting the probabilities based on the neighbors' connections to the previous node\n",
    "                    probabilities = []\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor == previous_node:\n",
    "                            probabilities.append(1/p)#prob = graph[current_node][neighbor].get('weight', 1) / p # Incorporating edge weights into probability\n",
    "                        elif graph.has_edge(previous_node, neighbor):                 # Note: there is a tradeoff between edge weights + p,q (i.e:\n",
    "                            probabilities.append(1)#prob = graph[current_node][neighbor].get('weight', 1)     # if p=2, q=0.5 but the weight of the last edge is much greater,\n",
    "                        else:                                                         # there is a larger probability of returning to that edge)\n",
    "                            probabilities.append(1/q)#prob = graph[current_node][neighbor].get('weight', 1) / q\n",
    "                        #probabilities.append(prob)\n",
    "\n",
    "                    # Normalize probabilities\n",
    "                    probabilities = numpy.array(probabilities, dtype = float)\n",
    "                    probabilities /= probabilities.sum()\n",
    "\n",
    "                    # Choose next node based on the transition probabilities\n",
    "                    next_node = numpy.random.choice(neighbors, p=probabilities)\n",
    "\n",
    "                walk.append(next_node)\n",
    "                previous_node = current_node\n",
    "                current_node = next_node\n",
    "\n",
    "        return walk\n",
    "\n",
    "def generate_random_walks(graph, steps, n, p, q): # generating random walks\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(n):\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(second_order_random_walk(graph, steps, n, p, q))\n",
    "    return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vectors(graph, steps, n, p, q):\n",
    "    # Generating vectors\n",
    "    create_graph(30000)   # 1048576\n",
    "    walks = generate_random_walks(graph, steps, n, p, q)\n",
    "    str_walks = [[str(n) for n in walk] for walk in walks]\n",
    "    model = Word2Vec(str_walks, vector_size=128, window=5, min_count=0, sg=0, workers=2, hs=0, epochs=1)\n",
    "    node_ids = list(model.wv.index_to_key)  # node ids\n",
    "    int_node_ids = []\n",
    "    for node_id in node_ids:\n",
    "        int_node_ids.append(int(node_id))\n",
    "    int_node_ids = numpy.array(int_node_ids)\n",
    "    vectors = (model.wv.vectors) # vectors\n",
    "    return vectors, int_node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(vectors, int_node_ids):\n",
    "    # Creating a dataset with just the genes, classification, and vectors\n",
    "    vector_data = pd.DataFrame(vectors)\n",
    "    vector_data['gene'] = int_node_ids\n",
    "\n",
    "    if node_df.index.name != 'id':\n",
    "        node_df.set_index('id', inplace=True)\n",
    "\n",
    "    disease_assoc_cat = numpy.array([node_df.loc[node_id]['disease_assoc_cat'] for node_id in int_node_ids])\n",
    "    vector_data['disease_assoc_cat'] = disease_assoc_cat\n",
    "\n",
    "    # vector_data.set_index('gene',inplace=True)\n",
    "\n",
    "    # Creating features\n",
    "    X = vector_data.iloc[:, :-1].values\n",
    "    y = vector_data['disease_assoc_cat'].values\n",
    "\n",
    "    # Splitting data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8)\n",
    "\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Initializing the classifier\n",
    "    mlp_model = MLPClassifier(activation='tanh', alpha=0.0001, hidden_layer_sizes=(100, 100, 50), learning_rate='adaptive', max_iter=400, solver='adam') # parameters found using GridSearchCV\n",
    "\n",
    "    # Train the classifier\n",
    "    mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = mlp_model.predict(X_test_scaled)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    return report\n",
    "    # # Evaluate the classifier\n",
    "    # accuracy = mlp_model.score(X_test, y_test)\n",
    "    # print(f'Accuracy: {accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_graph(n):\n",
    "    sampled_node_df = node_df.sample(n=n) # Taking random nodes and incident edges\n",
    "    edges = []\n",
    "    for n_index, n_row in sampled_node_df.iterrows():\n",
    "        for e_index, e_row in edge_df.iterrows():\n",
    "            if n_index == e_row['source'] or n_index == e_row['target']:\n",
    "                edges.append(e_row['source_target_key'])\n",
    "\n",
    "    # Convert each edge into a tuple\n",
    "    edge_tuples = lambda x: tuple(map(int,x.split(';')))\n",
    "\n",
    "    # Put all those tuples in a list\n",
    "    edge_list = list(map(edge_tuples, edges))\n",
    "\n",
    "    geneGraph.add_edges_from(edge_list)\n",
    "\n",
    "    # Weighting edges on DIOPT scores\n",
    "    diopt_dict = {}\n",
    "\n",
    "    for index, edge in enumerate(edge_list):\n",
    "        diopt_dict[edge] = edge_df.iloc[index]['interaction_count']\n",
    "\n",
    "    nx.set_edge_attributes(geneGraph, diopt_dict, 'weight')\n",
    "\n",
    "    # Add bidirectional edges based on reciprocal value\n",
    "    bidirectional_edges = []\n",
    "\n",
    "    for index, edge in enumerate(edge_list):\n",
    "        reciprocal = edge_df.iloc[index]['reciprocal']\n",
    "    if reciprocal:\n",
    "        reversed_edge = (edge[1], edge[0])\n",
    "        bidirectional_edges.append(reversed_edge)\n",
    "\n",
    "    # Adding edges to graph\n",
    "    geneGraph.add_edges_from(bidirectional_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
